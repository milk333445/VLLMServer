server:
  host: "0.0.0.0" 
  port: 8947
  uvicorn_log_level: "info"
  cuda: "0"

LLM_engines:
  Qwen2-7B-Instruct:
    model: "Qwen2-7B-Instruct"
    tokenizer: "Qwen2-7B-Instruct"
    dtype: "float16"
    tensor_parallel_size: 1
    gpu_memory_utilization: 0.25
    max_num_seqs: 20
    max_model_len: 16000
  Qwen1.5-14B-Chat:
    model: "Qwen1.5-14B-Chat"
    tokenizer: "Qwen1.5-14B-Chat"
    dtype: "float16"
    tensor_parallel_size: 1
    gpu_memory_utilization: 0.55
    max_num_seqs: 20
    max_model_len: 17072

embedding_models:
  m3e-base:
    model_name: "moka-ai/m3e-base"
    model_path: "./embedding_engine/model/embedding_model/m3e-base-model"
    tokenizer_path: "./embedding_engine/model/embedding_model/m3e-base-tokenizer"
    max_length: 512
    use_gpu: True
    use_float16: True
  
reranking_models:
  bge-reranker-large:
    model_name: 'BAAI/bge-reranker-large'
    model_path: "./embedding_engine/model/reranking_model/bge-reranker-large-model"
    tokenizer_path: "./embedding_engine/model/reranking_model/bge-reranker-large-tokenizer"  
    max_length: 512
    use_gpu: True  
    use_float16: True
