services:
  pytorch-llm:
    image: llm-max:latest 
    container_name: pytorch-max-llm
    command: tail -f /dev/null
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - /etc/localtime:/etc/localtime
      - /home/kuo/max:/usr/src/app
    working_dir: /usr/src/app
    ports:
            - "8888:8888"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    restart: unless-stopped
